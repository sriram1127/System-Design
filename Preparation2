Handling Log File
-----------------

Collection
Transportation
Storage
Data Analysis/Learning
Purging/Zip


Facebook Messenger/we chat/ whatsapp
------------------------------------
1. Send/read messages
2. Send msg to individual/group
3. Encryption messages
4. low latency, high consistency, follow sequence order
5. Reliability & availability
6. Block People
7. Change profile settings & pic
8. Online & Offline mode
9. push notifications for new messages
10. Status online
11. supports text & media messages

Components & technique
1. Client
2. Load Balancer
3. Chat Servers
4. Application servers
5. SQL Database for users
6. Hbase for messages
7. HTTP polling - Hanging GET
8. public-private key encryption
9. TTL for request & re-establish connections
10. Sequence for messages
11. send message - chat server - receive message - send ack
12. Store messages for clients (users/groups)
13. 50k connections by modern system. 10k servers for 500M
14. store for 10 years
15. friends Details storage
16. heart beat

1. HTTP Long Polling or web socketsor Hanging GET
2. Ajax Polling - HTTP Overheads
3. HBase 
4. Reed - solomon technique encoding to replicate and distribute

Web Crawler
-----------
1. types - html/audio/image/videos - MIME multipurpose Internet Mail Extensions
2. HTTP/FTP
3. defined to a location
4. robot.txt - Robots exclusion protocol
5. 15 billion pages/per month - 6200 pages per second
6. 100kb for 1 html page - 15 PB -> 2.2 PB memory(70%) max usage limit
7. BFS/DFS/Path ascending technique

process
Links Finder -> Connect to host -> document download -> extract unvisited links -> store & index of the content -> repeat
Main complexity lies in algorithm which ranks the web page.
web page might update often.
consistent hashing
take backup of the snapshots for recovery
crawler traps 
Bloom Filter - false positives
checksum for documents
parsing difficulty


Twitch/ video streaming sites
-----------------------------
Live or Offline Video Streaming
TCP/UDP
Some browsers dont supports UDP, - need some apps to run
Packets are transfered to CDN and HTTP transfer is used.
Client stores the chucks before few milliseconds and construct the frame
pause and go online should leave the old packets (javascript)
Should vary the pixel quality based on the download spead
Client ask the servers to give the peers and get the top few peers


