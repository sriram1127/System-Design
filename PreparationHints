TinyURL
--------
Length - 7 - 3500 billion possibilities
1000 requests per second - 110 years
Unique Id Generation - zookeeper - or Even/Odd id generation
26 + 26 + 10 = 62 chars
ToShortURL(), ToID() methods
Load Balancing 
Redis instances (Cache)
Consistent Hashing
URL -> Hash -> find the node on the cluster
Virtual Node - Hashing Algorithm to chose the node on the cluster
Uniform random
SQL server
Horizonal Sharding
Backup instances
Read & write operations per second 
GUII
Security Concerns

First Non repeating word 100 GB
-------------------------------
chars 'a' - 'z'
average word length - 6 
1 char - 1 byte in ASCII encoding
Trie - host name, list object
DoublyLinkedList - line, index of line
Parallelism 
26 servers
Round robin - 100 lines
English Dict - 5 MB 
single spaced ?
have special chars ?
Differentiate Caps and lower case ?


Rate Limiter
------------

can divide servers based on the Hashing of the clientId
Load Balancing
use array as circular queue
isAllowed(clientId)
System.currentTimeMillis();
clientId as Key

Map<Integer, HitCounter>

class HitCounter {
  longs hits[] = null; // milliseconds
  int cur = 0;
  public HitCounter() {
    initialize();
  }
  
  private void initialize() {
    hits[] = new int[100];
    Arrays.fill(Long.MAX_VALUE);
  }
}

Hit Counter - count requests for the last five minutes
------------------------------------------------------
timestamps may not be in order.
Distributed Application - scale - complex system

int[] count = new int[300]; total count
int[] times = new int[300]; time in seconds

counter.hit(timestamp) 
int idx = timestamp%300;
if times[idx] == timestamp count[idx]++;
if times[idx] > timestamp discard
if times[idx] < timestamp count[idx] = 1;

counter.getHits()
System.currentTimeMillis/1000 - times[idx] < 300

More servers/nodes
Distribute based on the hashing of the user email id
add up at the end
To maintain concurrency - use concurrent hashmap - lock the object


Product, Item Recommendation System
-------------------------------------
How much is the purchase gap ?
How many recommendation products ?
How big is the system ? Scaling
When to show the recommendations ?
Separate products based on departments ?


PrimaryKey(ItemA, ItemB), count
N * N connections
Graph Problem
Process the table and get recommendation each night
Back the daily pair count.
move to a server based on the hash of the product id
once the product is purchased, write or queue the product along with all the product bought along within one year.
if failed, can lookup the main purchase table.

Recommendation Process.
For each server, for each product maintain a min heap of size k and move the max count to the heap.
and store it to a recommendation table.
parallelism - lock to update the counter
substract the counter from prev year

Recommendation ALgorithm
co - occurence matrix
Symmetric matrix
Machine Learning
Age, Gender, Geographical location, Weather, Trend, Departments
If a million people bought TV and a box of eggs together then there must be some truth to the relationship. 
It is hard to come up with rules that can connect TV with eggs.
Train the regression model based on the analysis.
real time processing
map/reduce in Spark. 
Redis, Memcached, or DynamoDB
CAP theorem
Downtime for blue/green deployments.
https://www.coursera.org/lecture/ml-foundations/collaborative-filtering-people-who-bought-this-also-bought-CdmdR


Paste Bin
-----------
create a content, update the content, read the content
generate unique url for the content for read
content expires after some time
create timer for the content to expire
generate unique id 
generate url based on the unique id
use redis for frequently accessed content
distribute the request based on the userid
how many read and writes per second
can allowed to edit the content - need a lock on this 
what to show when the content expires ?
can reuse the key after content expiration ?
Does users need to login to create the content?
how big is the content ? limit on the content
Traffic and overloading issues - Adding and removing servers - consistent hashing
no of limits for the users to write on the server - security measures 
clearup cache after the records gets expired
More users join ? 
What to do in case of failures ?















